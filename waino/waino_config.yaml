data: "./data/bigger_training_data.parquet"

training_params:
  learning_rate: 0.0001
  batch_size: 256
  max_epochs: 5
  num_workers: 0
  log_every_n: 1
  accumulate_grad_batches: 4
  p_mask: 0.2
  min_length: 0
  mask_tokens: True
  holdout_prob: .1

net_params:
  d_model: 128
  max_length: 192
  n_layers: 2
  n_head: 4
  dim_ff: 128
  dropout: 0.2